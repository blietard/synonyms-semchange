{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from params import DECADES, WORDS_FOLDER, COHA_FREQ_FILE, DECADES_INDS, MIN_FREQ, MIN_LENGTH, HAMILTON_SGNS_FOLDER, SGNS_FOLDER\n",
    "from postags import replace_posTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = pd.read_csv(f'{WORDS_FOLDER}/{COHA_FREQ_FILE}', skip_blank_lines=True, encoding='utf-8', delimiter='\\t', dtype={'freq':'int64', 'word-cs':'str','PoS':'str','decade':'int8'})\n",
    "word_list = word_list.rename({\"word-cs\":\"word\"},axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3172840"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nan\n",
    "word_list = word_list.loc[word_list['word'].isnull() == False]\n",
    "word_list = word_list.loc[word_list['PoS'].isnull() == False]\n",
    "# remove useless decades\n",
    "word_list = word_list.loc[word_list['decade'].isin(DECADES_INDS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047597"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating targets list...\n",
      "Merging PoS tag and filtering...\n",
      "Nb of unique (word,PoS) after PoS selection :  323847\n",
      "Filtering with word length...\n",
      "Nb of unique (word,PoS) after Minimum Length :  323252\n",
      "Filtering with minimum frequency per decade...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering candidate (word,pos): 100%|██████████| 323252/323252 [00:16<00:00, 19121.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of unique (word,PoS) after Minimum Freq :  33890\n",
      "Final number of targets (unique (word, pos) ) :  33890\n",
      "Nb of targets per pos : \n",
      "ADJ : 7130\n",
      "N : 16571\n",
      "V : 10189\n"
     ]
    }
   ],
   "source": [
    "print('Creating targets list...')\n",
    "targets = word_list.copy()\n",
    "# Remove words that are not from the selected PoS\n",
    "print('Merging PoS tag and filtering...')\n",
    "targets['PoS'] = list(map(replace_posTag,targets['PoS']))\n",
    "targets = targets.loc[targets['PoS'].isnull() == False] # Remove none\n",
    "targets = targets.groupby(['word','PoS','decade'])['freq'].sum().reset_index() # Merge duplicate\n",
    "print('Nb of unique (word,PoS) after PoS selection : ', len(targets.groupby(['word','PoS'])))\n",
    "\n",
    "# Remove words that are too small\n",
    "print('Filtering with word length...')\n",
    "targets = targets.loc[targets['word'].str.len() >= MIN_LENGTH]\n",
    "print('Nb of unique (word,PoS) after Minimum Length : ', len(targets.groupby(['word','PoS'])))\n",
    "\n",
    "# Remove words that are not frequent enough in each decade\n",
    "print('Filtering with minimum frequency per decade...')\n",
    "to_keep = []\n",
    "wordpos_groups = targets.groupby(['word','PoS'])\n",
    "for wordpos, group in tqdm(wordpos_groups, desc='Filtering candidate (word,pos)'):\n",
    "    if group['freq'].min()>= MIN_FREQ and len(group)==len(DECADES_INDS):\n",
    "        to_keep += list(group.index)\n",
    "targets = targets.loc[to_keep]\n",
    "print('Nb of unique (word,PoS) after Minimum Freq : ', len(targets.groupby(['word','PoS'])))\n",
    "\n",
    "# targetfname = f\"{WORDS_FOLDER}/{TRGT_FILE}\"\n",
    "# targets.to_csv(targetfname, index=False, sep='\\t')\n",
    "# print('Targets list created as '+targetfname)\n",
    "print('Final number of targets (unique (word, pos) ) : ', len(targets.groupby(['word','PoS'])))\n",
    "print('Nb of targets per pos : ')\n",
    "for pos, group in targets.groupby('PoS'):\n",
    "    print(pos, ':', len(group.groupby('word')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['HamiltonSGNS_ind'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>PoS</th>\n",
       "      <th>decade</th>\n",
       "      <th>freq</th>\n",
       "      <th>HamiltonSGNS_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>a-goin</td>\n",
       "      <td>V</td>\n",
       "      <td>9</td>\n",
       "      <td>86</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>a-goin</td>\n",
       "      <td>V</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>a-goin</td>\n",
       "      <td>V</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>a-goin</td>\n",
       "      <td>V</td>\n",
       "      <td>12</td>\n",
       "      <td>171</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>a-goin</td>\n",
       "      <td>V</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455943</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455944</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455945</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455946</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455947</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372790 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word PoS  decade  freq  HamiltonSGNS_ind\n",
       "726      a-goin   V       9    86                -1\n",
       "727      a-goin   V      10   120                -1\n",
       "728      a-goin   V      11    75                -1\n",
       "729      a-goin   V      12   171                -1\n",
       "730      a-goin   V      13    45                -1\n",
       "...         ...  ..     ...   ...               ...\n",
       "1455943   zulus   N      15    16                -1\n",
       "1455944   zulus   N      16     6                -1\n",
       "1455945   zulus   N      17    11                -1\n",
       "1455946   zulus   N      18    21                -1\n",
       "1455947   zulus   N      19    11                -1\n",
       "\n",
       "[372790 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2ind_per_dec = dict()\n",
    "for dec_ind,dec in zip(DECADES_INDS,DECADES):\n",
    "    with open(f'{HAMILTON_SGNS_FOLDER}/{dec}-vocab.pkl','rb') as f_pkl:\n",
    "        vocab = pickle.load(f_pkl)\n",
    "    vocab2ind_per_dec[dec_ind] = dict(zip(vocab,range(len(vocab))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "372790it [00:25, 14356.34it/s]\n"
     ]
    }
   ],
   "source": [
    "for row_i, row in tqdm(targets.iterrows()):\n",
    "    try : \n",
    "        targets.loc[row_i,'HamiltonSGNS_ind'] = vocab2ind_per_dec[row.decade][row.word]\n",
    "    except KeyError as exc:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing relative freq: 359271it [00:09, 38301.69it/s]\n",
      "/tmp/ipykernel_19319/2830692126.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  targets['rel_freq'] = [ row['freq'] / decade_sum[row['decade']] for _, row in tqdm(targets.iterrows(), desc='Computing relative freq') ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>PoS</th>\n",
       "      <th>decade</th>\n",
       "      <th>freq</th>\n",
       "      <th>HamiltonSGNS_ind</th>\n",
       "      <th>rel_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>abandon</td>\n",
       "      <td>N</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>3937</td>\n",
       "      <td>5.250624e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>abandon</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>63</td>\n",
       "      <td>4045</td>\n",
       "      <td>8.118498e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>abandon</td>\n",
       "      <td>N</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>4407</td>\n",
       "      <td>7.150863e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>abandon</td>\n",
       "      <td>N</td>\n",
       "      <td>12</td>\n",
       "      <td>72</td>\n",
       "      <td>4505</td>\n",
       "      <td>7.892489e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>abandon</td>\n",
       "      <td>N</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "      <td>4433</td>\n",
       "      <td>6.357692e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455943</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>36343</td>\n",
       "      <td>1.820371e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455944</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>33160</td>\n",
       "      <td>6.998263e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455945</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>37980</td>\n",
       "      <td>1.297198e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455946</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>46611</td>\n",
       "      <td>2.321766e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455947</th>\n",
       "      <td>zulus</td>\n",
       "      <td>N</td>\n",
       "      <td>19</td>\n",
       "      <td>11</td>\n",
       "      <td>46575</td>\n",
       "      <td>1.082055e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359271 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word PoS  decade  freq  HamiltonSGNS_ind      rel_freq\n",
       "2525     abandon   N       9    38              3937  5.250624e-06\n",
       "2526     abandon   N      10    63              4045  8.118498e-06\n",
       "2527     abandon   N      11    57              4407  7.150863e-06\n",
       "2528     abandon   N      12    72              4505  7.892489e-06\n",
       "2529     abandon   N      13    56              4433  6.357692e-06\n",
       "...          ...  ..     ...   ...               ...           ...\n",
       "1455943    zulus   N      15    16             36343  1.820371e-06\n",
       "1455944    zulus   N      16     6             33160  6.998263e-07\n",
       "1455945    zulus   N      17    11             37980  1.297198e-06\n",
       "1455946    zulus   N      18    21             46611  2.321766e-06\n",
       "1455947    zulus   N      19    11             46575  1.082055e-06\n",
       "\n",
       "[359271 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = targets[targets.HamiltonSGNS_ind >= 0]\n",
    "\n",
    "# Append the relative frequency column ( freq / decade_total )\n",
    "decade_sum = targets.groupby(['decade'])['freq'].sum()\n",
    "targets['rel_freq'] = [ row['freq'] / decade_sum[row['decade']] for _, row in tqdm(targets.iterrows(), desc='Computing relative freq') ]\n",
    "\n",
    "\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ : 6453\n",
      "N : 16135\n",
      "V : 10073\n"
     ]
    }
   ],
   "source": [
    "for pos, group in targets.groupby('PoS'):\n",
    "    print(pos, ':', len(group.groupby('word')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.to_csv(f'{WORDS_FOLDER}/target_words.csv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_retrieve_per_pos_per_dec = dict()\n",
    "word_lists_per_pos = dict()\n",
    "\n",
    "pos_groups = targets.groupby('PoS')\n",
    "\n",
    "for pos in pos_groups.groups.keys():\n",
    "    ind_to_retrieve_per_dec = dict()\n",
    "    \n",
    "    dec_groups = pos_groups.get_group(pos).groupby('decade')\n",
    "    word_lists_per_pos[pos] = list(dec_groups.get_group(DECADES_INDS[0]).sort_values(['word'])['word'].values)\n",
    "\n",
    "    for dec in DECADES_INDS:\n",
    "        ind_to_retrieve_per_dec[dec] = dec_groups.get_group(dec).sort_values(['word'])['HamiltonSGNS_ind'].values\n",
    "    \n",
    "    ind_to_retrieve_per_pos_per_dec[pos] = ind_to_retrieve_per_dec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating matrices per decade: 100%|██████████| 11/11 [00:01<00:00, 10.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for dec_i, dec in tqdm(zip(DECADES_INDS, DECADES),total=len(DECADES),desc='Generating matrices per decade'):\n",
    "    mat = np.load(f'{HAMILTON_SGNS_FOLDER}/{dec}-w.npy')\n",
    "    for pos, ind_dec_dict in ind_to_retrieve_per_pos_per_dec.items():\n",
    "        indices = ind_dec_dict[dec_i]\n",
    "        pos_mat = mat[indices]\n",
    "        np.save(file=f'{SGNS_FOLDER}/{dec}_{pos}.npy',arr=pos_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ : 6453\n",
      "N : 16135\n",
      "V : 10073\n"
     ]
    }
   ],
   "source": [
    "for pos, word_list in word_lists_per_pos.items():\n",
    "    with open(f'{WORDS_FOLDER}/{pos}_list.pkl','wb') as f:\n",
    "        pickle.dump(file=f,obj=word_list)\n",
    "    print(pos,':',len(word_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synonyms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:15:33) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb0e797c1520a08a52f62b7983504799503e8c377ab3341546af98ade1280554"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
