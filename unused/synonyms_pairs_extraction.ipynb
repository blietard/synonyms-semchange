{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fernald.txt','r') as f:\n",
    "    text = f.read()\n",
    "lines = text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_next_entry(lines,start,end):\n",
    "    '''\n",
    "    Search entry in the list of lines `lines` between indices `start` and `end` (included).\n",
    "    Return the line number at the end of the entry, and the entry itself.\n",
    "    '''\n",
    "    searching_entry = True\n",
    "    current_nline = start\n",
    "    # Searching the first entry\n",
    "    while searching_entry and current_nline<end:\n",
    "        line = lines[current_nline]\n",
    "        if line == '       *       *       *       *       *':\n",
    "            searching_entry = False\n",
    "        current_nline +=1\n",
    "    entry_start = current_nline\n",
    "    # Searching the next entry\n",
    "    searching_next_entry = True\n",
    "    while searching_next_entry and current_nline<end:\n",
    "        line = lines[current_nline]\n",
    "        if line == '       *       *       *       *       *':\n",
    "            searching_next_entry = False\n",
    "        current_nline +=1\n",
    "    entry_end = current_nline-1\n",
    "    return (entry_end,lines[entry_start:entry_end])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(entry):\n",
    "   '''\n",
    "   Return the list of synonymous pairs found in an entry.\n",
    "   A pair is (ENTRY_HEAD, synonymous word).\n",
    "   `entry` must be a list of text lines.\n",
    "   '''\n",
    "   syns = list()\n",
    "   \n",
    "   headline = entry[1].split(',')\n",
    "\n",
    "   if len(headline) == 1:\n",
    "      head = headline[0][:-1].lower()\n",
    "   elif len(headline) > 1:\n",
    "      head = ''.join( [ head_part.strip() for head_part in headline]).lower()\n",
    "   else:\n",
    "      raise ValueError('No entry head found.')\n",
    "\n",
    "   if ' ' in head:\n",
    "      print(entry[1])\n",
    "      raise ValueError('Entry head is not a single word.')\n",
    "\n",
    "   syn_list_start = 0\n",
    "   while entry[syn_list_start]!='Synonyms:' and entry[syn_list_start]!='Synonym:':\n",
    "      syn_list_start +=1\n",
    "   syn_list_start += 2 #Skip 'Synonyms:' and following empty line.\n",
    "   syn_list_end = syn_list_start\n",
    "   while entry[syn_list_end]: #Search next empty line\n",
    "      syn_list_end +=1\n",
    "   synonyms_list = entry[syn_list_start:syn_list_end]\n",
    "\n",
    "   for line in synonyms_list:\n",
    "      words = [word for word in line.split(',') if word] #remove empty\n",
    "      for word in words:\n",
    "         syns.append( word.strip() )\n",
    "   \n",
    "   last_syn = syns.pop(-1)\n",
    "   syns.append( last_syn[:-1] ) #remove punctation at the end.\n",
    "\n",
    "   syns = [syn_word for syn_word in syns.copy() if ' ' not in syn_word  ] #remove compound word synonyms\n",
    "\n",
    "   return (head,syns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "partI_range = (453,22058)\n",
    "\n",
    "syn_pairs = dict()\n",
    "nline = partI_range[0]\n",
    "\n",
    "while nline < partI_range[1]:\n",
    "    nline, entry = extract_next_entry(lines, nline, partI_range[1])\n",
    "    if not entry:\n",
    "        break\n",
    "    head, syns = get_synonyms(entry)\n",
    "    syn_pairs[head] = syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./words/adjs_list.pickle','rb') as f:\n",
    "    adjs = set(pickle.load(f))\n",
    "with open('./words/nouns_list.pickle','rb') as f:\n",
    "    nouns = set(pickle.load(f))\n",
    "with open('./words/verbs_list.pickle','rb') as f:\n",
    "    verbs = set(pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 629/629 [00:00<00:00, 71112.89it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_syn_pairs = { 'A': dict(), 'N': dict() ,'V':dict()}\n",
    "\n",
    "for full_head, syns in tqdm(syn_pairs.items()):\n",
    "    full_head = full_head.split('_')\n",
    "    if len(full_head)>1:\n",
    "        head, pos = full_head[:2]\n",
    "    else:\n",
    "        head = full_head[0]\n",
    "        pos = ''\n",
    "        \n",
    "    if head in adjs and (pos=='a.' or not pos):\n",
    "        select = list()\n",
    "        for syn in syns:\n",
    "            if syn in adjs:\n",
    "                select.append(syn)\n",
    "        if select:\n",
    "            final_syn_pairs['A'][head] = select.copy()\n",
    "\n",
    "    elif head in nouns and (pos=='n.' or not pos):\n",
    "        select = list()\n",
    "        for syn in syns:\n",
    "            if syn in nouns:\n",
    "                select.append(syn)\n",
    "        if select:\n",
    "            final_syn_pairs['N'][head] = select.copy()\n",
    "\n",
    "    elif head in verbs and (pos=='v.' or not pos):\n",
    "        select = list()\n",
    "        for syn in syns:\n",
    "            if syn in verbs:\n",
    "                select.append(syn)\n",
    "        if select:\n",
    "            final_syn_pairs['V'][head] = select.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoS : A, nb heads : 143, nb pairs: 1450\n",
      "PoS : N, nb heads : 308, nb pairs: 2519\n",
      "PoS : V, nb heads : 110, nb pairs: 616\n"
     ]
    }
   ],
   "source": [
    "for pos in final_syn_pairs.keys():\n",
    "    print(f'PoS : {pos}, nb heads : {len(final_syn_pairs[pos])}, nb pairs: {sum( [ len(syns) for syns in final_syn_pairs[pos].values()] )}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in final_syn_pairs.keys():\n",
    "    with open(f'./words/words2graph_{pos}.txt','w',encoding='utf-8') as f:\n",
    "        for head in final_syn_pairs[pos].keys():\n",
    "            f.write(head)\n",
    "            for syn in final_syn_pairs[pos][head]:\n",
    "                f.write(' '+syn)\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./words/fernald_synonyms.pickle','wb') as f:\n",
    "    pickle.dump(final_syn_pairs, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('synonyms')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb931acade56343797ccf210d455f95f082cbfd7f4cc82030e6c7788404105f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
